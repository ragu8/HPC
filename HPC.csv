S No,Year,Title,Abstract,Authors,Journal
1,2019,Migrating parallel applications to the cloud: assessing cloud readiness based on parallel design decisions,"Parallel applications are the computational backbone of major industry trends and grand challenges in science. Whereas these applications are typically constructed for dedicated High Performance Computing clusters and supercomputers, the cloud emerges as attractive execution environment, which provides on-demand resource provisioning and a pay-per-use model. However, cloud environments require specific application properties that may restrict parallel application design. As a result, design trade-offs are required to simultaneously maximize parallel performance and benefit from cloud-specific characteristics. In this paper, we present a novel approach to assess the cloud readiness of parallel applications based on the design decisions made. By discovering and understanding the implications of these parallel design decisions on an application’s cloud readiness, our approach supports the migration of parallel applications to the cloud. We introduce an assessment procedure, its underlying meta model, and a corresponding instantiation to structure this multi-dimensional design space. For evaluation purposes, we present an extensive case study comprising three parallel applications and discuss their cloud readiness based on our approach.","Stefan Kehrer,Stefan Kehrer,Wolfgang Blochinger,Wolfgang Blochinger",IEEE Transactions on Cloud Computing
2,2013,High performance cloud computing,"Today's high performance computing systems are typically managed and operated by individual organizations in private. Computing demand is fluctuating, however, resulting in periods where dedicated resources are either underutilized or overloaded. A cloud-based Infrastructure-as-a-Service (IaaS) approach for high performance computing applications promises cost savings and more flexibility. In this model virtualized and elastic resources are utilized on-demand from large cloud computing service providers to construct virtual clusters exactly matching a customer's specific requirements. This paper gives an overview on the current state of high performance cloud computing technology and we describe the underlying virtualization techniques and management methods. Furthermore, we present a novel approach to use high speed cluster interconnects like InfiniBand in a high performance cloud computing environment.","Viktor Mauch,Viktor Mauch,M. Kunze,Marcel Kunze,Marius Hillenbrand,Marius Hillenbrand",Future Generation Computer Systems
3,2016,An Analysis of Public Clouds Elasticity in the Execution of Scientific Applications: a Survey,"Elasticity can be seen as the ability of a system to increase or decrease the computing resources allocated in a dynamic and on demand way. It is an important feature provided by cloud computing, that has been widely used in web applications and is also gaining attention in the scientific community. Considering the possibilities of using elasticity in this context, a question arises: ""Are the available public cloud solutions suitable to provide elasticity to scientific applications?"" To answer the question, in a first moment we present a survey on the use of cloud computing in scientific scenarios, providing an overview of the subject. Next, we describe the elasticity mechanisms offered by major public cloud providers and analyzes the limitations of the solutions in providing elasticity for scientific applications. As the main contribution of the article, we also present an analysis over some initiatives that are being developed to overcome the current challenges. In our opinion, current computational clouds are developing rapidly but have not yet reached the necessary maturity level to meet all scientific applications elasticity requirements. We expect that in the coming years the efforts being taken by numerous researchers in this area identify and address these challenges and lead to better and more mature technologies that will improve cloud computing practices.","Guilherme Galante,Guilherme Galante,Luis C. E. Bona,Luis C. E. Bona,Antonio Roberto Mury,Antonio Roberto Mury,Bruno Schulze,Bruno Schulze,Rodrigo Rosa Righi,Rodrigo da Rosa Righi",IEEE Transactions on Cloud Computing
4,2013,Performance analysis of HPC applications in the cloud,"The scalability of High Performance Computing (HPC) applications depends heavily on the efficient support of network communications in virtualized environments. However, Infrastructure as a Service (IaaS) providers are more focused on deploying systems with higher computational power interconnected via high-speed networks rather than improving the scalability of the communication middleware. This paper analyzes the main performance bottlenecks in HPC application scalability on the Amazon EC2 Cluster Compute platform: (1) evaluating the communication performance on shared memory and a virtualized 10 Gigabit Ethernet network; (2) assessing the scalability of representative HPC codes, the NAS Parallel Benchmarks, using an important number of cores, up to 512; (3) analyzing the new cluster instances (CC2), both in terms of single instance performance, scalability and cost-efficiency of its use; (4) suggesting techniques for reducing the impact of the virtualization overhead in the scalability of communication-intensive HPC codes, such as the direct access of the Virtual Machine to the network and reducing the number of processes per instance; and (5) proposing the combination of message-passing with multithreading as the most scalable and cost-effective option for running HPC applications on the Amazon EC2 Cluster Compute platform. Highlights? Performance results of HPC applications in the cloud using up to 512 cores. ? Up-to-date performance evaluation of the Amazon EC2 Cluster Compute platform. ? High Performance Cloud Computing applications rely on scalable communication. ? Proposal of new techniques for increasing scalability of HPC codes in the cloud. ? Using several levels of parallelism is key for HPC scalability in the cloud.","Roberto R. Expósito,Roberto R. Expósito,Guillermo L. Taboada,Guillermo L. Taboada,Sabela Ramos,Sabela Ramos,Juan Touriño,Juan Touriño,Ramón Doallo,Ramón Doallo",Future Generation Computer Systems
5,2013,"The Who, What, Why, and How of High Performance Computing in the Cloud","Cloud computing is emerging as an alternative to supercomputers for some of the high-performance computing (HPC) applications that do not require a fully dedicated machine. With cloud as an additional deployment option, HPC users are faced with the challenges of dealing with highly heterogeneous resources, where the variability spans across a wide range of processor configurations, interconnections, virtualization environments, and pricing rates and models. In this paper, we take a holistic viewpoint to answer the question - why and who should choose cloud for HPC, for what applications, and how should cloud be used for HPC? To this end, we perform a comprehensive performance evaluation and analysis of a set of benchmarks and complex HPC applications on a range of platforms, varying from supercomputers to clouds. Further, we demonstrate HPC performance improvements in cloud using alternative lightweight virtualization mechanisms - thin VMs and OS-level containers, and hyper visor- and application-level CPU affinity. Next, we analyze the economic aspects and business models for HPC in clouds. We believe that is an important area that has not been sufficiently addressed by past research. Overall results indicate that current public clouds are cost-effective only at small scale for the chosen HPC applications, when considered in isolation, but can complement supercomputers using business models such as cloud burst and application-aware mapping.","Abhishek Gupta,Abhishek Gupta,Laxmikant V. Kalé,Laxmikant V. Kale,Filippo Gioachin,Filippo Gioachin,Verdi March,Verdi March,Chun Hui Suen,Chun Hui Suen,Chun Hui Suen,Bu-Sung Lee,Bu-Sung Lee,Bu-Sung Lee,Paolo Faraboschi,Paolo Faraboschi,Richard Kaufmann,Richard Kaufmann,Dejan Milojicic,Dejan Milojicic",IEEE Transactions on Cloud Computing
6,2011,Converting a High Performance Application to an Elastic Cloud Application,"Over the past decade, high performance applications have embraced parallel programming and computing models. While parallel computing offers advantages such as good utilization of dedicated hardware resources, it also has several drawbacks such as poor fault-tolerance, scalability, and ability to harness available resources during run-time. The advent of cloud computing presents a viable and promising alternative to parallel computing because of its advantages in offering a distributed computing model. In this work, we establish directives that serve as guidelines for the design and implementation or identification of a suitable cloud computing framework to build or convert a high performance application to run in the cloud. We show that following these directives leads to an elastic implementation that has better scalability, run-time resource adaptability, fault tolerance, and portability across cloud computing platforms, while requiring minimal effort and intervention from the user. We illustrate this by converting an MPI implementation of replica exchange, a parallel tempering molecular dynamics application, to an elastic cloud application using the Work Queue framework that adheres to these directive. We observe better scalability and resource adaptability of this elastic application on multiple platforms, including a homogeneous cluster environment (SGE) and heterogeneous cloud computing environments such as Microsoft Azure and Amazon EC2.","Dinesh Rajan,Dinesh Rajan,Anthony Canino,Anthony Canino,Jesús A. Izaguirre,Jesús A. Izaguirre,Douglas Thain,Douglas Thain",IEEE Transactions on Cloud Computing
7,2019,Amazon Elastic Compute Cloud (EC2) versus In-House HPC Platform: A Cost Analysis,"While High Performance Computing (HPC) centers continuously evolve to provide more computing power to their users, we observe a wish for the convergence between Cloud Computing (CC) and High Performance Computing (HPC) platforms, with the commercial hope to see Cloud Computing (CC) infrastructures to eventually replace in-house facilities. If we exclude the performance point of view where many previous studies highlight a non-negligible overhead induced by the virtualization layer at the heart of every Cloud middleware when running a HPC workload, the question of the real cost-effectiveness is often left aside with the intuition that, most probably, the instances offered by the Cloud providers are competitive from a cost point of view. In this article, we wanted to assert (or infirm) this intuition by analyzing what composes the Total Cost of Ownership (TCO) of an in-house HPC facility operated internally since 2007. This Total Cost of Ownership (TCO) model is then used to compare with the induced cost that would have been required to run the same platform (and the same workload) over a competitive Cloud IaaS offer. Our approach to address this price comparison is three-fold. First we propose a theoretical price-performance model based on the study of the actual Cloud instances proposed by one of the major Cloud IaaS actors: Amazon Elastic Compute Cloud (EC2). Then, based on the HPC facility TCO analysis we propose a hourly price comparison between our in-house cluster and the equivalent EC2 instances. Finally, based on the experimental benchmarking on the local cluster and on the Cloud instances we propose an update of the former theoretical price model to reflect the real system performance. The results obtained advocate in general for the acquisition of an in-house HPC facility, which balances the common intuition in favor of Cloud Computing platforms, would they be provided by the reference Cloud provider worldwide.","Joseph Emeras,Joseph Emeras,Sébastien Varrette,Sébastien Varrette,Valentin Plugaru,Valentin Plugaru,Pascal Bouvry,Pascal Bouvry",IEEE Transactions on Cloud Computing
8,2011,Evaluation of HPC Applications on Cloud,"HPC applications are increasingly being used in academia and laboratories for scientific research and in industries for business and analytics. Cloud computing offers the benefits of virtualization, elasticity of resources and elimination of cluster setup cost and time to HPC applications users. However, poor network performance, performance variation and OS noise are some of the challenges for execution of HPC applications on Cloud. In this paper, we propose that Cloud can be viable platform for some HPC applications depending upon application characteristics such as communication volume and pattern and sensitivity to OS noise and scale. We present an evaluation of the performance and cost tradeoffs of HPC applications on a range of platforms varying from Cloud (with and without virtualization) to HPC-optimized cluster. Our results show that Cloud is viable platform for some applications, specifically, non communicationintensive applications such as embarrassingly parallel and tree-structured computations up to high processor count and for communication-intensive applications up to low processor count.","Abhishek Gupta,Abhishek Gupta,Dejan Milojicic,Dejan Milojicic",2011 Sixth Open Cirrus Summit
9,2010,High performance cloud computing a view of scientific applications,"Scientific computing often requires the availability of a massive number of computers for performing large scale experiments. Traditionally, these needs have been addressed by using high-performance computing solutions and installed facilities such as clusters and super computers, which are difficult to setup, maintain, and operate. Cloud computing provides scientists with a completely new model of utilizing the computing infrastructure. Compute resources, storage resources, as well as applications, can be dynamically provisioned (and integrated within the existing infrastructure) on a pay per use basis. These resources can be released when they are no more needed. Such services are often offered within the context of a Service Level Agreement (SLA), which ensure the desired Quality of Service (QoS). Aneka, an enterprise Cloud computing solution, harnesses the power of compute resources by relying on private and public Clouds and delivers to users the desired QoS. Its flexible and service based infrastructure supports multiple programming paradigms that make Aneka address a variety of different scenarios: from finance applications to computational science. As examples of scientific computing in the Cloud, we present a preliminary case study on using Aneka for the classification of gene expression data and the execution of fMRI brain imaging workflow.","Christian Vecchiola,Suraj Pandey,Rajkumar Buyya","International Symposium on Pervasive Systems, Algorithms, and Networks"
10,2018,"HPC Cloud for Scientific and Business Applications: Taxonomy, Vision, and Research Challenges","High performance computing (HPC) clouds are becoming an alternative to on-premise clusters for executing scientific applications and business analytics services. Most research efforts in HPC cloud aim to understand the cost benefit of moving resource-intensive applications from on-premise environments to public cloud platforms. Industry trends show that hybrid environments are the natural path to get the best of the on-premise and cloud resources—steady (and sensitive) workloads can run on on-premise resources and peak demand can leverage remote resources in a pay-as-you-go manner. Nevertheless, there are plenty of questions to be answered in HPC cloud, which range from how to extract the best performance of an unknown underlying platform to what services are essential to make its usage easier. Moreover, the discussion on the right pricing and contractual models to fit small and large users is relevant for the sustainability of HPC clouds. This article brings a survey and taxonomy of efforts in HPC cloud and a vision on what we believe is ahead of us, including a set of research challenges that, once tackled, can help advance businesses and scientific discoveries. This becomes particularly relevant due to the fast increasing wave of new HPC applications coming from big data and artificial intelligence.","Marco A. S. Netto,Marco A. S. Netto,Rodrigo N. Calheiros,Rodrigo N. Calheiros,Eduardo R. Rodrigues,Eduardo R. Rodrigues,Renato L. F. Cunha,Renato L. F. Cunha,Rajkumar Buyya,Rajkumar Buyya",ACM Computing Surveys
